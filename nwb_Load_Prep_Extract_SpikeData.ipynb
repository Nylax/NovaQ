 {
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7772090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NWB file...\n",
      "Preprocessing recording...\n",
      "Binning into 1 ms time windows...\n",
      "Extracting traces...\n",
      "Creating binned spike matrix...\n",
      "\n",
      "âœ… Binned spike tensor saved to: binned_spike_tensor.npy\n",
      "Shape: (1, 1391945, 45) â€” [batch, channels, time]\n"
     ]
    }
   ],
   "source": [
    "#Loading sub-P29-16-05-14-retina02-left_ecephys.nwb from https://dandiarchive.org/dandiset/000034/0.211030.0713/files?location=sub-P29-16-05-14-retina02-left&page=1\n",
    "\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ---- File setup ----\n",
    "nwb_path = r\"C:\\Users\\synap\\Downloads\\sub_P29_16_05_14_retina02_left_ecephys.nwb\"\n",
    "assert os.path.exists(nwb_path), f\"NWB file not found: {nwb_path}\"\n",
    "\n",
    "# ---- Load raw ecephys data from NWB ----\n",
    "print(\"Loading NWB file...\")\n",
    "recording = se.read_nwb_recording(nwb_path)\n",
    "\n",
    "# Optional: restrict to a time segment (e.g., first 60 seconds)\n",
    "recording = recording.frame_slice(\n",
    "    start_frame=0,\n",
    "    end_frame=int(recording.get_sampling_frequency() * 60)\n",
    ")\n",
    "\n",
    "# ---- Preprocess: bandpass filter and global reference ----\n",
    "print(\"Preprocessing recording...\")\n",
    "recording = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n",
    "recording = spre.common_reference(recording, reference='global')\n",
    "\n",
    "# ---- Bin the spikes into 1 ms windows ----\n",
    "print(\"Binning into 1 ms time windows...\")\n",
    "fs = recording.get_sampling_frequency()\n",
    "duration_sec = recording.get_num_frames() / fs\n",
    "bin_size_ms = 1\n",
    "bin_size_samples = int(fs * (bin_size_ms / 1000))\n",
    "num_bins = int(duration_sec * 1000)\n",
    "\n",
    "# Get traces: shape (time, channels)\n",
    "print(\"Extracting traces...\")\n",
    "traces = recording.get_traces().T  # (time, channels)\n",
    "\n",
    "# Threshold spike detection\n",
    "threshold = 5 * np.std(traces)\n",
    "binary_spikes = (traces > threshold).astype(int)\n",
    "\n",
    "# Bin spikes by 1 ms\n",
    "print(\"Creating binned spike matrix...\")\n",
    "binned_spikes = np.array([\n",
    "    np.max(binary_spikes[i:i+bin_size_samples], axis=0)\n",
    "    for i in range(0, binary_spikes.shape[0], bin_size_samples)\n",
    "])  # shape: (bins, channels)\n",
    "\n",
    "# Transpose and expand: shape (1, channels, time)\n",
    "binned_spikes = binned_spikes.T  # (channels, time)\n",
    "binned_spikes = np.expand_dims(binned_spikes, axis=0)  # (1, channels, time)\n",
    "\n",
    "# ---- Save for training ----\n",
    "output_path = \"binned_spike_tensor.npy\"\n",
    "np.save(output_path, binned_spikes)\n",
    "\n",
    "print(f\"\\nâœ… Binned spike tensor saved to: {output_path}\")\n",
    "print(f\"Shape: {binned_spikes.shape} â€” [batch, channels, time]\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f286804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available acquisition keys:\n",
      " - ElectricalSeries\n",
      "\n",
      "âœ… Found ElectricalSeries under key: 'ElectricalSeries'\n",
      "\n",
      "ðŸ“ Shape of electrical data: (3148820, 1024)\n",
      "   â†’ Time samples: 3148820\n",
      "   â†’ Channels: 1024\n"
     ]
    }
   ],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "# Path to your NWB file\n",
    "nwb_path = r\"C:\\Users\\synap\\Downloads\\sub_P29_16_05_14_retina02_left_ecephys.nwb\"\n",
    "\n",
    "# Open the NWB file\n",
    "with NWBHDF5IO(nwb_path, 'r') as io:\n",
    "    nwbfile = io.read()\n",
    "\n",
    "    print(\"\\nAvailable acquisition keys:\")\n",
    "    acquisition_keys = list(nwbfile.acquisition.keys())\n",
    "    for key in acquisition_keys:\n",
    "        print(\" -\", key)\n",
    "\n",
    "    # Try to find the first ElectricalSeries key\n",
    "    electrical_series = None\n",
    "    for key in acquisition_keys:\n",
    "        obj = nwbfile.acquisition[key]\n",
    "        if 'ElectricalSeries' in str(type(obj)):\n",
    "            electrical_series = obj\n",
    "            print(f\"\\nâœ… Found ElectricalSeries under key: '{key}'\")\n",
    "            break\n",
    "\n",
    "    if electrical_series is not None:\n",
    "        data_shape = electrical_series.data.shape\n",
    "        print(f\"\\nðŸ“ Shape of electrical data: {data_shape}\")\n",
    "        print(f\"   â†’ Time samples: {data_shape[0]}\")\n",
    "        print(f\"   â†’ Channels: {data_shape[1]}\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ No ElectricalSeries found in acquisition.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "020fc468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NWB file...\n",
      "Recording duration: 135.73 seconds\n",
      "Preprocessing recording...\n",
      "Binning into 1 ms time windows...\n",
      "Extracting traces...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 10.6 GiB for an array with shape (1024, 1392011) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Get filtered traces (time, channels)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting traces...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m traces \u001b[38;5;241m=\u001b[39m recording\u001b[38;5;241m.\u001b[39mget_traces()  \u001b[38;5;66;03m# shape: (time, channels)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Threshold spike detection\u001b[39;00m\n\u001b[0;32m     39\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(traces)\n",
      "File \u001b[1;32mc:\\Users\\synap\\anaconda3\\Lib\\site-packages\\spikeinterface\\core\\baserecording.py:330\u001b[0m, in \u001b[0;36mBaseRecording.get_traces\u001b[1;34m(self, segment_index, start_frame, end_frame, channel_ids, order, return_scaled, cast_unsigned)\u001b[0m\n\u001b[0;32m    328\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget_num_samples()\n\u001b[0;32m    329\u001b[0m end_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(end_frame, num_samples)) \u001b[38;5;28;01mif\u001b[39;00m end_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_samples\n\u001b[1;32m--> 330\u001b[0m traces \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget_traces(start_frame\u001b[38;5;241m=\u001b[39mstart_frame, end_frame\u001b[38;5;241m=\u001b[39mend_frame, channel_indices\u001b[38;5;241m=\u001b[39mchannel_indices)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\synap\\anaconda3\\Lib\\site-packages\\spikeinterface\\preprocessing\\common_reference.py:183\u001b[0m, in \u001b[0;36mCommonReferenceRecordingSegment.get_traces\u001b[1;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_traces\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_frame, end_frame, channel_indices):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# Let's do the case with group_indices equal None as that is easy\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;66;03m# We need all the channels to calculate the reference\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m         traces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_recording_segment\u001b[38;5;241m.\u001b[39mget_traces(start_frame, end_frame, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_channel_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\synap\\anaconda3\\Lib\\site-packages\\spikeinterface\\preprocessing\\filter.py:180\u001b[0m, in \u001b[0;36mFilterRecordingSegment.get_traces\u001b[1;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward-backward\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msos\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 180\u001b[0m         filtered_traces \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39msosfiltfilt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoeff, traces_chunk, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         b, a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoeff\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\signal\\_signaltools.py:4463\u001b[0m, in \u001b[0;36msosfiltfilt\u001b[1;34m(sos, x, axis, padtype, padlen)\u001b[0m\n\u001b[0;32m   4461\u001b[0m (y, zf) \u001b[38;5;241m=\u001b[39m sosfilt(sos, ext, axis\u001b[38;5;241m=\u001b[39maxis, zi\u001b[38;5;241m=\u001b[39mzi \u001b[38;5;241m*\u001b[39m x_0)\n\u001b[0;32m   4462\u001b[0m y_0 \u001b[38;5;241m=\u001b[39m axis_slice(y, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m-> 4463\u001b[0m (y, zf) \u001b[38;5;241m=\u001b[39m sosfilt(sos, axis_reverse(y, axis\u001b[38;5;241m=\u001b[39maxis), axis\u001b[38;5;241m=\u001b[39maxis, zi\u001b[38;5;241m=\u001b[39mzi \u001b[38;5;241m*\u001b[39m y_0)\n\u001b[0;32m   4464\u001b[0m y \u001b[38;5;241m=\u001b[39m axis_reverse(y, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   4465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\signal\\_signaltools.py:4342\u001b[0m, in \u001b[0;36msosfilt\u001b[1;34m(sos, x, axis, zi)\u001b[0m\n\u001b[0;32m   4340\u001b[0m x_shape, zi_shape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape, zi\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   4341\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(x, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m-> 4342\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x, dtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# make a copy, can modify in place\u001b[39;00m\n\u001b[0;32m   4343\u001b[0m zi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(np\u001b[38;5;241m.\u001b[39mreshape(zi, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_sections, \u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m   4344\u001b[0m sos \u001b[38;5;241m=\u001b[39m sos\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 10.6 GiB for an array with shape (1024, 1392011) and data type float64"
     ]
    }
   ],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ---- File setup ----\n",
    "nwb_path = r\"C:\\Users\\synap\\Downloads\\sub_P29_16_05_14_retina02_left_ecephys.nwb\"\n",
    "assert os.path.exists(nwb_path), f\"NWB file not found: {nwb_path}\"\n",
    "\n",
    "# ---- Load raw ecephys data from NWB ----\n",
    "print(\"Loading NWB file...\")\n",
    "recording = se.read_nwb_recording(nwb_path)\n",
    "\n",
    "# Optional: use only first 60 seconds for memory efficiency\n",
    "fs = recording.get_sampling_frequency()\n",
    "duration_sec = recording.get_num_frames() / fs\n",
    "print(f\"Recording duration: {duration_sec:.2f} seconds\")\n",
    "\n",
    "recording = recording.frame_slice(\n",
    "    start_frame=0,\n",
    "    end_frame=int(fs * 60)\n",
    ")\n",
    "\n",
    "# ---- Preprocess: bandpass filter and global reference ----\n",
    "print(\"Preprocessing recording...\")\n",
    "recording = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n",
    "recording = spre.common_reference(recording, reference='global')\n",
    "\n",
    "# ---- Bin the spikes into 1 ms windows ----\n",
    "print(\"Binning into 1 ms time windows...\")\n",
    "bin_size_ms = 1\n",
    "bin_size_samples = int(fs * (bin_size_ms / 1000))\n",
    "\n",
    "# Get filtered traces (time, channels)\n",
    "print(\"Extracting traces...\")\n",
    "traces = recording.get_traces()  # shape: (time, channels)\n",
    "\n",
    "# Threshold spike detection\n",
    "threshold = 5 * np.std(traces)\n",
    "binary_spikes = (traces > threshold).astype(int)  # shape: (time, channels)\n",
    "\n",
    "# Bin by taking the max spike presence per channel in each 1 ms window\n",
    "print(\"Creating binned spike matrix...\")\n",
    "binned_spikes = np.array([\n",
    "    np.max(binary_spikes[i:i+bin_size_samples], axis=0)\n",
    "    for i in range(0, binary_spikes.shape[0], bin_size_samples)\n",
    "])  # shape: (bins, channels)\n",
    "\n",
    "# Transpose to (channels, bins) and expand to (1, channels, bins)\n",
    "binned_spikes = binned_spikes.T\n",
    "binned_spikes = np.expand_dims(binned_spikes, axis=0)\n",
    "\n",
    "# ---- Save for training ----\n",
    "output_path = \"binned_spike_tensor.npy\"\n",
    "np.save(output_path, binned_spikes)\n",
    "\n",
    "print(f\"\\nâœ… Binned spike tensor saved to: {output_path}\")\n",
    "print(f\"Shape: {binned_spikes.shape} â€” [batch, channels, time]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "609d14f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording loaded at 23199.090358491783 Hz\n"
     ]
    }
   ],
   "source": [
    "#step 1\n",
    "from spikeinterface.extractors import read_nwb_recording\n",
    "import spikeinterface.preprocessing as spre\n",
    "import numpy as np\n",
    "\n",
    "nwb_path = r\"C:\\Users\\synap\\Downloads\\sub_P29_16_05_14_retina02_left_ecephys.nwb\"\n",
    "recording = read_nwb_recording(nwb_path)\n",
    "\n",
    "# Use first 60 seconds only\n",
    "fs = recording.get_sampling_frequency()\n",
    "recording = recording.frame_slice(start_frame=0, end_frame=int(fs * 60))\n",
    "print(f\"Recording loaded at {fs} Hz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd4b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing in 12 chunks of 5s...\n"
     ]
    }
   ],
   "source": [
    "#Step2- Preprocessing and chunking setup\n",
    "# Apply bandpass + common reference\n",
    "recording = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n",
    "recording = spre.common_reference(recording, reference='global')\n",
    "\n",
    "# Chunk and bin settings\n",
    "chunk_duration = 5  # seconds\n",
    "bin_size_ms = 1\n",
    "bin_size_samples = int(fs * (bin_size_ms / 1000))\n",
    "samples_per_chunk = int(fs * chunk_duration)\n",
    "total_samples = recording.get_num_frames()\n",
    "num_chunks = total_samples // samples_per_chunk\n",
    "\n",
    "print(f\"Processing in {num_chunks} chunks of {chunk_duration}s...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8354826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ Processing chunk 1/12...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 908. MiB for an array with shape (1024, 116176) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m samples_per_chunk\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ†’ Processing chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m traces \u001b[38;5;241m=\u001b[39m recording\u001b[38;5;241m.\u001b[39mget_traces(start_frame\u001b[38;5;241m=\u001b[39mstart, end_frame\u001b[38;5;241m=\u001b[39mend)  \u001b[38;5;66;03m# (time, channels)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(traces)\n\u001b[0;32m     12\u001b[0m binary_spikes \u001b[38;5;241m=\u001b[39m (traces \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[1;32mc:\\Users\\synap\\anaconda3\\Lib\\site-packages\\spikeinterface\\core\\baserecording.py:330\u001b[0m, in \u001b[0;36mBaseRecording.get_traces\u001b[1;34m(self, segment_index, start_frame, end_frame, channel_ids, order, return_scaled, cast_unsigned)\u001b[0m\n\u001b[0;32m    328\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget_num_samples()\n\u001b[0;32m    329\u001b[0m end_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(end_frame, num_samples)) \u001b[38;5;28;01mif\u001b[39;00m end_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_samples\n\u001b[1;32m--> 330\u001b[0m traces \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget_traces(start_frame\u001b[38;5;241m=\u001b[39mstart_frame, end_frame\u001b[38;5;241m=\u001b[39mend_frame, channel_indices\u001b[38;5;241m=\u001b[39mchannel_indices)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\synap\\anaconda3\\Lib\\site-packages\\spikeinterface\\preprocessing\\common_reference.py:183\u001b[0m, in \u001b[0;36mCommonReferenceRecordingSegment.get_traces\u001b[1;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_traces\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_frame, end_frame, channel_indices):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# Let's do the case with group_indices equal None as that is easy\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;66;03m# We need all the channels to calculate the reference\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m         traces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_recording_segment\u001b[38;5;241m.\u001b[39mget_traces(start_frame, end_frame, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_channel_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\synap\\anaconda3\\Lib\\site-packages\\spikeinterface\\preprocessing\\filter.py:180\u001b[0m, in \u001b[0;36mFilterRecordingSegment.get_traces\u001b[1;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward-backward\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msos\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 180\u001b[0m         filtered_traces \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39msosfiltfilt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoeff, traces_chunk, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         b, a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoeff\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\signal\\_signaltools.py:4461\u001b[0m, in \u001b[0;36msosfiltfilt\u001b[1;34m(sos, x, axis, padtype, padlen)\u001b[0m\n\u001b[0;32m   4459\u001b[0m zi\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m [n_sections] \u001b[38;5;241m+\u001b[39m zi_shape\n\u001b[0;32m   4460\u001b[0m x_0 \u001b[38;5;241m=\u001b[39m axis_slice(ext, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m-> 4461\u001b[0m (y, zf) \u001b[38;5;241m=\u001b[39m sosfilt(sos, ext, axis\u001b[38;5;241m=\u001b[39maxis, zi\u001b[38;5;241m=\u001b[39mzi \u001b[38;5;241m*\u001b[39m x_0)\n\u001b[0;32m   4462\u001b[0m y_0 \u001b[38;5;241m=\u001b[39m axis_slice(y, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   4463\u001b[0m (y, zf) \u001b[38;5;241m=\u001b[39m sosfilt(sos, axis_reverse(y, axis\u001b[38;5;241m=\u001b[39maxis), axis\u001b[38;5;241m=\u001b[39maxis, zi\u001b[38;5;241m=\u001b[39mzi \u001b[38;5;241m*\u001b[39m y_0)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\signal\\_signaltools.py:4342\u001b[0m, in \u001b[0;36msosfilt\u001b[1;34m(sos, x, axis, zi)\u001b[0m\n\u001b[0;32m   4340\u001b[0m x_shape, zi_shape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape, zi\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   4341\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(x, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m-> 4342\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x, dtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# make a copy, can modify in place\u001b[39;00m\n\u001b[0;32m   4343\u001b[0m zi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(np\u001b[38;5;241m.\u001b[39mreshape(zi, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_sections, \u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m   4344\u001b[0m sos \u001b[38;5;241m=\u001b[39m sos\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 908. MiB for an array with shape (1024, 116176) and data type float64"
     ]
    }
   ],
   "source": [
    "#Step 3 - Binning loop (with progress and low memory)\n",
    "binned_chunks = []\n",
    "\n",
    "for chunk_idx in range(num_chunks):\n",
    "    start = chunk_idx * samples_per_chunk\n",
    "    end = start + samples_per_chunk\n",
    "\n",
    "    print(f\"â†’ Processing chunk {chunk_idx+1}/{num_chunks}...\")\n",
    "\n",
    "    traces = recording.get_traces(start_frame=start, end_frame=end)  # (time, channels)\n",
    "    threshold = 5 * np.std(traces)\n",
    "    binary_spikes = (traces > threshold).astype(np.uint8)\n",
    "\n",
    "    # Bin spikes by 1 ms (take max across bin size)\n",
    "    chunk_binned = np.array([\n",
    "        np.max(binary_spikes[i:i + bin_size_samples], axis=0)\n",
    "        for i in range(0, binary_spikes.shape[0], bin_size_samples)\n",
    "    ])  # shape: (bins, channels)\n",
    "\n",
    "    binned_chunks.append(chunk_binned)\n",
    "\n",
    "print(\"âœ… All chunks processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab5abe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 256 channels for 60 seconds at 23199.090358491783 Hz.\n"
     ]
    }
   ],
   "source": [
    "from spikeinterface.extractors import read_nwb_recording\n",
    "import spikeinterface.preprocessing as spre\n",
    "import numpy as np\n",
    "\n",
    "# Load NWB file and limit to 256 channels\n",
    "nwb_path = r\"C:\\Users\\synap\\Downloads\\sub_P29_16_05_14_retina02_left_ecephys.nwb\"\n",
    "recording = read_nwb_recording(nwb_path)\n",
    "channel_ids = recording.get_channel_ids()[:256]\n",
    "recording = recording.channel_slice(channel_ids=channel_ids)\n",
    "\n",
    "# Limit duration to 60 seconds max\n",
    "fs = recording.get_sampling_frequency()\n",
    "recording = recording.frame_slice(start_frame=0, end_frame=int(fs * 60))\n",
    "print(f\"Loaded {len(channel_ids)} channels for 60 seconds at {fs} Hz.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cdd459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30 chunks of 2 seconds each.\n"
     ]
    }
   ],
   "source": [
    "# Apply filtering and reference\n",
    "recording = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n",
    "recording = spre.common_reference(recording, reference='global')\n",
    "\n",
    "chunk_duration_sec = 2\n",
    "bin_size_ms = 1\n",
    "bin_size_samples = int(fs * (bin_size_ms / 1000))\n",
    "samples_per_chunk = int(fs * chunk_duration_sec)\n",
    "total_samples = recording.get_num_frames()\n",
    "num_chunks = total_samples // samples_per_chunk\n",
    "\n",
    "print(f\"Processing {num_chunks} chunks of {chunk_duration_sec} seconds each.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d44b752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ Processing chunk 1/30...\n",
      "â†’ Processing chunk 2/30...\n",
      "â†’ Processing chunk 3/30...\n",
      "â†’ Processing chunk 4/30...\n",
      "â†’ Processing chunk 5/30...\n",
      "â†’ Processing chunk 6/30...\n",
      "â†’ Processing chunk 7/30...\n",
      "â†’ Processing chunk 8/30...\n",
      "â†’ Processing chunk 9/30...\n",
      "â†’ Processing chunk 10/30...\n",
      "â†’ Processing chunk 11/30...\n",
      "â†’ Processing chunk 12/30...\n",
      "â†’ Processing chunk 13/30...\n",
      "â†’ Processing chunk 14/30...\n",
      "â†’ Processing chunk 15/30...\n",
      "â†’ Processing chunk 16/30...\n",
      "â†’ Processing chunk 17/30...\n",
      "â†’ Processing chunk 18/30...\n",
      "â†’ Processing chunk 19/30...\n",
      "â†’ Processing chunk 20/30...\n",
      "â†’ Processing chunk 21/30...\n",
      "â†’ Processing chunk 22/30...\n",
      "â†’ Processing chunk 23/30...\n",
      "â†’ Processing chunk 24/30...\n",
      "â†’ Processing chunk 25/30...\n",
      "â†’ Processing chunk 26/30...\n",
      "â†’ Processing chunk 27/30...\n",
      "â†’ Processing chunk 28/30...\n",
      "â†’ Processing chunk 29/30...\n",
      "â†’ Processing chunk 30/30...\n",
      "âœ… All chunks processed.\n"
     ]
    }
   ],
   "source": [
    "binned_chunks = []\n",
    "\n",
    "for chunk_idx in range(num_chunks):\n",
    "    start = chunk_idx * samples_per_chunk\n",
    "    end = start + samples_per_chunk\n",
    "    print(f\"â†’ Processing chunk {chunk_idx+1}/{num_chunks}...\")\n",
    "\n",
    "    traces = recording.get_traces(start_frame=start, end_frame=end)\n",
    "    threshold = 5 * np.std(traces)\n",
    "    binary_spikes = (traces > threshold).astype(np.uint8)\n",
    "\n",
    "    chunk_binned = np.array([\n",
    "        np.max(binary_spikes[i:i + bin_size_samples], axis=0)\n",
    "        for i in range(0, binary_spikes.shape[0], bin_size_samples)\n",
    "    ])\n",
    "    binned_chunks.append(chunk_binned)\n",
    "\n",
    "print(\"âœ… All chunks processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b1aaea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final tensor shape: (1, 256, 60540)\n",
      "âœ… Saved to binned_spike_tensor_256ch.npy\n"
     ]
    }
   ],
   "source": [
    "# Concatenate along time axis\n",
    "final_binned = np.concatenate(binned_chunks, axis=0).T  # shape: (channels, time)\n",
    "final_tensor = np.expand_dims(final_binned, axis=0)     # shape: (1, channels, time)\n",
    "\n",
    "print(f\"Final tensor shape: {final_tensor.shape}\")\n",
    "np.save(\"binned_spike_tensor_256ch.npy\", final_tensor)\n",
    "print(\"âœ… Saved to binned_spike_tensor_256ch.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8a79a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (1, 256, 60540)\n",
      "Torch shape: torch.Size([1, 256, 60540])\n"
     ]
    }
   ],
   "source": [
    "#Cell 1: Load binned spike tensor\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load saved binned spike tensor\n",
    "data = np.load(\"binned_spike_tensor_256ch.npy\")\n",
    "print(\"Loaded shape:\", data.shape)  # (1, 256, 60540)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "spike_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "print(\"Torch shape:\", spike_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3e0cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define the autoencoder\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpikeAutoencoder(nn.Module):\n",
    "    def __init__(self, input_channels=256, embedding_dim=16):\n",
    "        super(SpikeAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),  # time / 2\n",
    "            nn.Conv1d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),  # collapse time\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 64),\n",
    "            nn.Unflatten(1, (64, 1)),\n",
    "            nn.ConvTranspose1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose1d(128, input_channels, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ea03b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented shape for training: torch.Size([256, 1000, 60])\n"
     ]
    }
   ],
   "source": [
    "# Step 3 â€” Segment the spike tensor by time and prepare for Conv1D over time\n",
    "segment_len = 1000  # 1000 ms = 1 second segments\n",
    "\n",
    "# Unfold along time â†’ shape: (1, 256, num_segments, 1000)\n",
    "segments = spike_tensor.unfold(dimension=2, size=segment_len, step=segment_len)\n",
    "\n",
    "# Reshape to: (segments, channels, time) â†’ then permute for Conv1D over time\n",
    "segments = segments.squeeze(0).permute(0, 2, 1)  # (segments, time, channels)\n",
    "\n",
    "print(\"Segmented shape for training:\", segments.shape)  # (e.g., 60, 1000, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "446f3714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\synap\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:610: UserWarning: Using a target size (torch.Size([16, 1000, 60])) that is different to the input size (torch.Size([16, 1, 60])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 3.7948\n",
      "Epoch 2 | Loss: 1.6617\n",
      "Epoch 3 | Loss: 0.0211\n",
      "Epoch 4 | Loss: 0.0164\n",
      "Epoch 5 | Loss: 0.0164\n",
      "Epoch 6 | Loss: 0.0164\n",
      "Epoch 7 | Loss: 0.0164\n",
      "Epoch 8 | Loss: 0.0164\n",
      "Epoch 9 | Loss: 0.0164\n",
      "Epoch 10 | Loss: 0.0164\n"
     ]
    }
   ],
   "source": [
    "#step 4  model $ training loop \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class SpikeAutoencoder(nn.Module):\n",
    "    def __init__(self, input_channels=256, embedding_dim=16):\n",
    "        super(SpikeAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_channels, out_channels=128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),  # â†’ (batch, 64, 1)\n",
    "            nn.Flatten(),             # â†’ (batch, 64)\n",
    "            nn.Linear(64, embedding_dim)  # â†’ (batch, embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 64),\n",
    "            nn.Unflatten(1, (64, 1)),     # â†’ (batch, 64, 1)\n",
    "            nn.ConvTranspose1d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(128, input_channels, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid()  # Ensure output in [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x shape: (batch, time, channels)\n",
    "        x = x.permute(0, 2, 1)      # â†’ (batch, channels, time)\n",
    "        z = self.encoder(x)         # compressed\n",
    "        x_recon = self.decoder(z)   # reconstruct\n",
    "        x_recon = x_recon.permute(0, 2, 1)  # back to (batch, time, channels)\n",
    "        return x_recon, z\n",
    "\n",
    "# Prepare DataLoader\n",
    "dataset = TensorDataset(segments)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "model = SpikeAutoencoder(input_channels=segments.shape[2])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0.0\n",
    "    for batch in loader:\n",
    "        x = batch[0]  # shape: (batch, time, channels)\n",
    "        x_recon, z = model(x)\n",
    "        loss = loss_fn(x_recon, x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} | Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4218243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed embeddings shape: (256, 16)\n",
      "âœ… Saved to compressed_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "#step 5 Extract compressed vecotrs and save embeddings \n",
    "model.eval()\n",
    "embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        x = batch[0]\n",
    "        _, z = model(x)  # shape: (batch, embedding_dim)\n",
    "        embeddings.append(z)\n",
    "\n",
    "# Concatenate and convert to NumPy\n",
    "compressed = torch.cat(embeddings, dim=0).cpu().numpy()\n",
    "print(\"Compressed embeddings shape:\", compressed.shape)\n",
    "\n",
    "# Save to disk\n",
    "np.save(\"compressed_embeddings.npy\", compressed)\n",
    "print(\"âœ… Saved to compressed_embeddings.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8dd253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
[<img src="https://qbraid-static.s3.amazonaws.com/logos/Launch_on_qBraid_black.png" width="150">](https://account.qbraid.com?gitHubUrl=<YOUR GIT .git LINK>)
